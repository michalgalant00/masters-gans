# DCGAN - Spectrogram Generation Module

DCGAN to implementacja Deep Convolutional Generative Adversarial Network przeznaczona do generowania spektrogramÃ³w dÅºwiÄ™kÃ³w silnikÃ³w spalinowych. ModuÅ‚ wykorzystuje standardowÄ… architekturÄ™ DCGAN pracujÄ…cÄ… na obrazach spektrogramÃ³w 2D.

## ğŸ¯ Cel Projektu

Generowanie realistycznych spektrogramÃ³w dÅºwiÄ™kÃ³w silnikÃ³w poprzez:

- Trening na spektrogramach wygenerowanych z rzeczywistych prÃ³bek audio
- Wykorzystanie klasycznej architektury DCGAN 2D
- Generowanie obrazÃ³w spektrogramÃ³w o rozdzielczoÅ›ci 128x128 pikseli
- **Zapis sampli w formacie NumPy (.npy)** dla lepszej jakoÅ›ci i elastycznoÅ›ci

## ğŸ—ï¸ Architektura

### Generator (`generator.py`)

- **Input**: Wektor szumu z rozkÅ‚adu normalnego [batch_size, latent_dim, 1, 1]
- **Output**: Spektrogram [batch_size, 1, 128, 128]
- **Architektura**: SieÄ‡ transposed convolution 2D z upsampling
- **Warstwy**: Linear â†’ 5x ConvTranspose2D â†’ Tanh
- **Pattern**: 4Ã—4 â†’ 8Ã—8 â†’ 16Ã—16 â†’ 32Ã—32 â†’ 64Ã—64 â†’ 128Ã—128

### Discriminator (`discriminator.py`)

- **Input**: Spektrogram [batch_size, 1, 128, 128]
- **Output**: PrawdopodobieÅ„stwo autentycznoÅ›ci [batch_size, 1]
- **Architektura**: SieÄ‡ convolution 2D z downsampling
- **Warstwy**: 5x Conv2D â†’ Sigmoid
- **Pattern**: 128Ã—128 â†’ 64Ã—64 â†’ 32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8 â†’ 4Ã—4 â†’ 1

### Training Pipeline (`training.py`)

- **Loss**: Binary Cross-Entropy (standard DCGAN)
- **Optimizer**: Adam (lr=0.0002, Î²1=0.5)
- **Strategy**: RÃ³wnoczesny trening generatora i dyskryminatora
- **Samples**: Zapisywane w formacie .npy (bez strat kompresji)

## ğŸ“ Struktura Kodu

```
dcgan_src/
â”œâ”€â”€ config.json              # GÅ‚Ã³wna konfiguracja produkcyjna
â”œâ”€â”€ config_test.json         # Konfiguracja testowa (szybka)
â”œâ”€â”€ config_template.json     # Szablon z komentarzami
â”œâ”€â”€ config_loader.py         # System Å‚adowania konfiguracji
â”œâ”€â”€ config.py                # Legacy config (backward compatibility)
â”œâ”€â”€ generator.py             # Architektura generatora DCGAN
â”œâ”€â”€ discriminator.py         # Architektura dyskryminatora DCGAN
â”œâ”€â”€ training.py              # Pipeline treningu DCGAN
â”œâ”€â”€ dataset.py               # Åadowanie datasetu spektrogramÃ³w
â”œâ”€â”€ metrics.py               # Zbieranie metryk dla obrazÃ³w
â”œâ”€â”€ npy_to_images.py         # Konwerter NumPy â†’ obrazy
â”œâ”€â”€ NPY_FORMAT_README.md     # Dokumentacja formatu .npy
â”œâ”€â”€ checkpoints.py           # ZarzÄ…dzanie checkpoint'ami
â”œâ”€â”€ analytics.py             # Analiza post-training
â”œâ”€â”€ convergence_detector.py  # Detekcja konwergencji
â”œâ”€â”€ advanced_monitoring.py   # Monitoring zasobÃ³w
â””â”€â”€ advanced_metrics.py      # Zaawansowane metryki obrazÃ³w
```

## âš™ï¸ Konfiguracja

### Podstawowe Parametry

```json
{
  "model": {
    "latent_dim": 100, // Wymiar przestrzeni latentnej
    "features_g": 64, // Liczba feature maps w generatorze
    "features_d": 64, // Liczba feature maps w dyskryminatorze
    "image_size": 128, // Rozmiar spektrogramu (128x128)
    "channels": 1 // KanaÅ‚y (1 = grayscale)
  },
  "training": {
    "batch_size": 64, // Rozmiar batcha
    "epochs": 200, // Liczba epok
    "learning_rate": 0.0002, // WspÃ³Å‚czynnik uczenia
    "beta1": 0.5 // Beta1 dla Adam optimizer
  }
}
```

### Rodzaje Konfiguracji

1. **`config.json`** - Produkcyjna (200 epok, batch=64, image_size=128)
2. **`config_test.json`** - Testowa (10 epok, batch=8, image_size=64)
3. **`config_template.json`** - Szablon z szczegÃ³Å‚owymi komentarzami

## ğŸš€ Uruchomienie

### Podstawowe UÅ¼ycie

```bash
# DomyÅ›lna konfiguracja
python DCGAN.py

# Konfiguracja testowa (szybka)
python DCGAN.py --config config_test

# WÅ‚asna konfiguracja
python DCGAN.py --config custom_config.json
```

### CLI Overrides

```bash
# Nadpisanie parametrÃ³w treningu
python DCGAN.py --epochs 100 --batch-size 32 --learning-rate 0.0001

# Parametry modelu
python DCGAN.py --image-size 64 --features-g 32 --features-d 32

# UÅ¼ycie CPU
python DCGAN.py --device cpu

# WÅ‚asny katalog wyjÅ›ciowy
python DCGAN.py --output-dir my_experiment
```

## ğŸ“Š Metryki i Monitoring

### Automatyczne Logowanie

- **Epoch Statistics**: Straty generatora/dyskryminatora, gradient norms
- **Iteration Details**: SzczegÃ³Å‚owe logi co 100 iteracji
- **Checkpoint Metrics**: FID, IS scores per checkpoint

### Struktura WyjÅ›Ä‡

```
output_dcgan/
â”œâ”€â”€ epochs_statistics/
â”‚   â”œâ”€â”€ epoch_statistics.csv      # Statystyki per epoka
â”‚   â”œâ”€â”€ checkpoint_metrics.csv    # Metryki jakoÅ›ci modelu
â”‚   â””â”€â”€ experiment_config.json    # Snapshot konfiguracji
â”œâ”€â”€ samples/                       # ğŸ†• NOWY FORMAT!
â”‚   â”œâ”€â”€ epoch_001.npy             # Sample NumPy (surowe dane)
â”‚   â”œâ”€â”€ epoch_005.npy             # Format: (batch, channels, H, W)
â”‚   â”œâ”€â”€ epoch_001_grid.png        # Opcjonalne: grid z konwertera
â”‚   â””â”€â”€ epoch_001_images/         # Opcjonalne: indywidualne obrazy
â”‚       â”œâ”€â”€ epoch_001_sample_01.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ checkpoint_epoch_10.tar   # Rolling buffer (max 2)
â”‚   â”œâ”€â”€ best_model.tar           # Najlepszy model
â”‚   â””â”€â”€ final_model.tar          # KoÅ„cowy stan
â”œâ”€â”€ single_epochs_statistics/
â”‚   â”œâ”€â”€ epoch_1/
â”‚   â”‚   â””â”€â”€ epoch_1_iterations.csv
â”‚   â””â”€â”€ epoch_N/...
â””â”€â”€ plots/
    â”œâ”€â”€ epoch_loss_curves.png     # Auto-generated
    â”œâ”€â”€ gradient_norms.png
    â”œâ”€â”€ generated_samples_grid.png
    â””â”€â”€ convergence_analysis.png
```

## ğŸ’¾ Nowy Format Sampli (.npy)

DCGAN teraz zapisuje sample w formacie NumPy zamiast PNG dla lepszej jakoÅ›ci:

```bash
# Konwertuj sample do obrazÃ³w
python dcgan_src/npy_to_images.py output_dcgan/samples/epoch_001.npy

# Wszystkie pliki w katalogu
python dcgan_src/npy_to_images.py --batch-convert output_dcgan/samples/

# SzczegÃ³Å‚y: dcgan_src/NPY_FORMAT_README.md
```

## ğŸ”§ Zaawansowane Funkcje

### Image Quality Metrics

- **FID** (FrÃ©chet Inception Distance)
- **IS** (Inception Score)
- **SSIM** (Structural Similarity Index)
- **LPIPS** (Learned Perceptual Image Patch Similarity)

### Convergence Detection

- Monitoring stabilnoÅ›ci loss functions
- Early stopping przy mode collapse
- Adaptive learning rate scheduling

### Resource Monitoring

- Real-time monitoring GPU/CPU usage
- Memory tracking per batch
- Performance profiling per epoch

## ğŸ–¼ï¸ Spectrogram Processing

### Format SpektrogramÃ³w

- **Resolution**: 128Ã—128 pikseli (production) / 64Ã—64 (test)
- **Channels**: 1 (grayscale)
- **Format**: PNG, normalized [0, 1]
- **Frequency Range**: 0-11kHz (dla 22kHz audio)

### Preprocessing Pipeline

1. Audio â†’ STFT (Short-Time Fourier Transform)
2. Magnitude spectrum calculation
3. Log-scale transformation
4. Normalization to [0, 1]
5. Resize to target resolution

## ğŸ› ï¸ Wymagania Systemowe

### Minimalne (config_test)

- GPU: 4GB VRAM
- RAM: 8GB
- Storage: 2GB

### Rekomendowane (config produkcyjne)

- GPU: RTX 4090 (24GB VRAM) lub RTX 3080+ (10GB+)
- RAM: 16GB+
- Storage: 20GB+

## ğŸ“ˆ PrzykÅ‚adowe Rezultaty

Po 200 epokach treningu:

- **Generator Loss**: ~1.0-3.0 (BCE)
- **Discriminator Loss**: ~0.5-1.5 (BCE)
- **FID Score**: <50 (dobra jakoÅ›Ä‡)
- **Training Time**: ~12h na RTX 4090

## ğŸ” Debugowanie

### CzÄ™ste Problemy

1. **Mode Collapse**

   ```bash
   # Zmniejsz learning rate
   python DCGAN.py --learning-rate 0.0001

   # ZwiÄ™ksz regularyzacjÄ™
   # Dodaj noise do dyskryminatora w config
   ```

2. **Discriminator Too Strong**

   ```bash
   # Balansuj trening
   python DCGAN.py --learning-rate 0.0002  # dla obu sieci
   ```

3. **CUDA Out of Memory**

   ```bash
   python DCGAN.py --batch-size 16 --image-size 64
   ```

4. **Brak spektrogramÃ³w**
   ```bash
   # SprawdÅº Å›cieÅ¼ki w config.json
   "dataset": {
     "spectrograms_path": "spectrograms/"
   }
   ```

### Monitoring JakoÅ›ci

```bash
# SprawdÅº postÄ™p treningu
tail -f output_dcgan/epochs_statistics/epoch_statistics.csv

# Obejrzyj wygenerowane prÃ³bki
ls output_dcgan/checkpoints/*/samples/
```

## ğŸ¨ Generowanie PrÃ³bek

### ğŸ†• Nowy Format NumPy (.npy)

DCGAN zapisuje teraz sample w formacie NumPy dla lepszej jakoÅ›ci:

```bash
# Basic conversion
python dcgan_src/npy_to_images.py output_dcgan/samples/epoch_001.npy

# Grid format
python dcgan_src/npy_to_images.py output_dcgan/samples/epoch_001.npy --mode grid

# Batch convert all files
python dcgan_src/npy_to_images.py --batch-convert output_dcgan/samples/

# Custom format and quality
python dcgan_src/npy_to_images.py epoch_001.npy --format jpeg --quality 95
```

### Programmatic Access

```python
import numpy as np

# Load samples
samples = np.load('output_dcgan/samples/epoch_001.npy')
print(f"Shape: {samples.shape}")  # (batch, channels, height, width)
print(f"Range: [{samples.min():.3f}, {samples.max():.3f}]")

# Access individual sample
first_sample = samples[0]  # Shape: (1, 64, 64) for grayscale
```

### Sample Grid Generation

- Automatyczne generowanie prÃ³bek co epokÄ™
- Format: (batch_size, 1, 64x64) dla testÃ³w, (batch_size, 1, 128x128) produkcyjnie
- Zapis w formacie .npy bez strat kompresji

### Custom Generation

```python
# Wygeneruj wÅ‚asne spektrogramy
from dcgan_src.generator import DCGANGenerator
import torch
import numpy as np

generator = DCGANGenerator()
generator.load_state_dict(torch.load('best_model.tar')['generator'])
noise = torch.randn(9, 100, 1, 1)
samples = generator(noise)

# Save as .npy
samples_np = samples.detach().cpu().numpy()
samples_np = (samples_np + 1.0) / 2.0  # Denormalize
np.save('my_samples.npy', samples_np)
```

## ğŸ”„ Pipeline Audio â†’ Spektrogram â†’ Audio

1. **Audio â†’ Spektrogram**: STFT preprocessing
2. **Spektrogram â†’ GAN**: DCGAN training/generation
3. **Spektrogram â†’ Audio**: Griffin-Lim reconstruction

### Reconstruction Quality

- **Original**: High fidelity (ÅºrÃ³dÅ‚owy STFT)
- **Generated**: Medium fidelity (artifacts z Griffin-Lim)
- **Improvement**: UÅ¼ywaj WaveGAN dla lepszej jakoÅ›ci audio

## ğŸ§ª Experimenty i Tuning

### Hyperparameter Ranges

- **Learning Rate**: 0.0001-0.0005
- **Batch Size**: 16-128 (zaleÅ¼y od GPU)
- **Features**: 32-128 (trade-off speed/quality)
- **Image Size**: 64, 128, 256

### Ablation Studies

- WpÅ‚yw batch size na stabilnoÅ›Ä‡
- Features_g vs features_d balance
- Image resolution vs training time

---

**Autor**: Projekt magisterski  
**Ostatnia aktualizacja**: SierpieÅ„ 2025  
**Licencja**: MIT
