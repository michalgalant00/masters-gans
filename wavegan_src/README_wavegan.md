# WaveGAN - Audio Generation Module

WaveGAN to implementacja Generative Adversarial Network przeznaczona do generowania 2-sekundowych pr√≥bek audio d≈∫wiƒôk√≥w silnik√≥w spalinowych. Modu≈Ç wykorzystuje architekturƒô WGAN-GP (Wasserstein GAN with Gradient Penalty) pracujƒÖcƒÖ bezpo≈õrednio na surowych pr√≥bkach audio.

## üéØ Cel Projektu

Generowanie realistycznych d≈∫wiƒôk√≥w silnik√≥w spalinowych poprzez:

- Trening na rzeczywistych pr√≥bkach audio (44.1kHz, 2 sekundy)
- Wykorzystanie architektury 1D konwolucyjnej
- Implementacjƒô WGAN-GP dla stabilnego treningu

## üèóÔ∏è Architektura

### Generator (`generator.py`)

- **Input**: Wektor szumu z rozk≈Çadu normalnego [batch_size, latent_dim]
- **Output**: Pr√≥bka audio [batch_size, 1, 44100]
- **Architektura**: Sieƒá transposed convolution 1D z upsampling
- **Warstwy**: FC ‚Üí 6x ConvTranspose1D ‚Üí Tanh

### Discriminator (`discriminator.py`)

- **Input**: Pr√≥bka audio [batch_size, 1, 44100]
- **Output**: Prawdopodobie≈Ñstwo autentyczno≈õci [batch_size, 1]
- **Architektura**: Sieƒá convolution 1D z downsampling
- **Warstwy**: 6x Conv1D ‚Üí FC ‚Üí Linear output

### Training Pipeline (`training.py`)

- **Loss**: WGAN-GP z gradient penalty
- **Optimizer**: Adam (lr=0.0001, Œ≤1=0.5, Œ≤2=0.9)
- **Strategy**: n_critic=5 (5 krok√≥w dyskryminatora na 1 krok generatora)

## üìÅ Struktura Kodu

```
wavegan_src/
‚îú‚îÄ‚îÄ config.json              # G≈Ç√≥wna konfiguracja produkcyjna
‚îú‚îÄ‚îÄ config_test.json         # Konfiguracja testowa (szybka)
‚îú‚îÄ‚îÄ config_template.json     # Szablon z komentarzami
‚îú‚îÄ‚îÄ config_loader.py         # System ≈Çadowania konfiguracji
‚îú‚îÄ‚îÄ generator.py             # Architektura generatora
‚îú‚îÄ‚îÄ discriminator.py         # Architektura dyskryminatora
‚îú‚îÄ‚îÄ training.py              # Pipeline treningu
‚îú‚îÄ‚îÄ dataset.py               # ≈Åadowanie datasetu audio
‚îú‚îÄ‚îÄ metrics.py               # Zbieranie metryk
‚îú‚îÄ‚îÄ checkpoints.py           # ZarzƒÖdzanie checkpoint'ami
‚îú‚îÄ‚îÄ analytics.py             # Analiza post-training
‚îú‚îÄ‚îÄ convergence_detector.py  # Detekcja konwergencji
‚îî‚îÄ‚îÄ advanced_monitoring.py   # Monitoring zasob√≥w
```

## ‚öôÔ∏è Konfiguracja

### Podstawowe Parametry

```json
{
  "model": {
    "latent_dim": 100, // Wymiar przestrzeni latentnej
    "model_dim": 128, // Podstawowy wymiar modelu
    "kernel_len": 25 // D≈Çugo≈õƒá kernela konwolucyjnego
  },
  "training": {
    "batch_size": 128, // Rozmiar batcha
    "epochs": 5000, // Liczba epok
    "learning_rate": 0.0001, // Wsp√≥≈Çczynnik uczenia
    "n_critic": 5, // Kroki dyskryminatora/generator
    "gp_weight": 10.0 // Waga gradient penalty
  },
  "audio": {
    "sample_rate": 22050, // Czƒôstotliwo≈õƒá pr√≥bkowania
    "audio_length_seconds": 2.0,
    "audio_length_samples": 44100
  }
}
```

### Rodzaje Konfiguracji

1. **`config.json`** - Produkcyjna (5000 epok, batch=128)
2. **`config_test.json`** - Testowa (15 epok, batch=8, mniejszy model)
3. **`config_template.json`** - Szablon z szczeg√≥≈Çowymi komentarzami

## üöÄ Uruchomienie

### Podstawowe U≈ºycie

```bash
# Domy≈õlna konfiguracja
python WaveGAN.py

# Konfiguracja testowa (szybka)
python WaveGAN.py --config config_test

# W≈Çasna konfiguracja
python WaveGAN.py --config custom_config.json
```

### CLI Overrides

```bash
# Nadpisanie parametr√≥w treningu
python WaveGAN.py --epochs 1000 --batch-size 64 --learning-rate 0.0002

# U≈ºycie CPU
python WaveGAN.py --device cpu

# W≈Çasny katalog wyj≈õciowy
python WaveGAN.py --output-dir my_experiment
```

### Tylko Generowanie

```bash
# Wygeneruj 10 pr√≥bek z wytrenowanego modelu
python WaveGAN.py --generate-only 10
```

## üìä Metryki i Monitoring

### Automatyczne Logowanie

- **Epoch Statistics**: Straty, gradient norms, u≈ºycie zasob√≥w
- **Iteration Details**: Szczeg√≥≈Çowe logi co 100 iteracji
- **Checkpoint Metrics**: STOI, PESQ, MCD scores per checkpoint

### Struktura Wyj≈õƒá

```
output_wavegan/
‚îú‚îÄ‚îÄ epochs_statistics/
‚îÇ   ‚îú‚îÄ‚îÄ epoch_statistics.csv      # Statystyki per epoka
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_metrics.csv    # Metryki jako≈õci modelu
‚îÇ   ‚îî‚îÄ‚îÄ experiment_config.json    # Snapshot konfiguracji
‚îú‚îÄ‚îÄ checkpoints/
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_epoch_10.tar   # Rolling buffer (max 2)
‚îÇ   ‚îú‚îÄ‚îÄ best_model.tar           # Najlepszy model
‚îÇ   ‚îî‚îÄ‚îÄ final_model.tar          # Ko≈Ñcowy stan
‚îú‚îÄ‚îÄ single_epochs_statistics/
‚îÇ   ‚îú‚îÄ‚îÄ epoch_1/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ epoch_1_iterations.csv
‚îÇ   ‚îî‚îÄ‚îÄ epoch_N/...
‚îî‚îÄ‚îÄ plots/
    ‚îú‚îÄ‚îÄ epoch_loss_curves.png     # Auto-generated
    ‚îú‚îÄ‚îÄ gradient_norms.png
    ‚îî‚îÄ‚îÄ convergence_analysis.png
```

## üîß Zaawansowane Funkcje

### Convergence Detection

- Automatyczna detekcja konwergencji na podstawie stabilno≈õci loss
- Early stopping przy wykryciu overfitting
- Adaptive learning rate scheduling

### Resource Monitoring

- Real-time monitoring GPU/CPU usage
- Memory tracking and optimization
- Performance profiling per epoch

### Quality Metrics

- **STOI** (Short-Time Objective Intelligibility)
- **PESQ** (Perceptual Evaluation of Speech Quality)
- **MCD** (Mel-Cepstral Distortion)
- **FAD** (Fr√©chet Audio Distance)

## üõ†Ô∏è Wymagania Systemowe

### Minimalne (config_test)

- GPU: 4GB VRAM
- RAM: 8GB
- Storage: 5GB

### Rekomendowane (config produkcyjne)

- GPU: RTX 4090 (24GB VRAM)
- RAM: 32GB+
- Storage: 50GB+

## üìà Przyk≈Çadowe Rezultaty

Po 5000 epokach treningu:

- **Generator Loss**: ~-50 do -100 (WGAN-GP)
- **Discriminator Loss**: ~-20 do -50 (WGAN-GP)
- **STOI Score**: >0.7 (dobra jako≈õƒá)
- **Training Time**: ~48h na RTX 4090

## üîç Debugowanie

### Czƒôste Problemy

1. **CUDA Out of Memory**

   ```bash
   python WaveGAN.py --batch-size 32 --num-workers 2
   ```

2. **Brak datasetu**

   ```bash
   # Sprawd≈∫ ≈õcie≈ºki w config.json
   "dataset": {
     "base_path": "../01_dataset_prep/dataset-processed/final"
   }
   ```

3. **Mode Collapse**
   - Zwiƒôksz gradient penalty weight: `"gp_weight": 15.0`
   - Zmniejsz learning rate: `"learning_rate": 0.00005`

### Monitoring Treningu

```bash
# Obserwuj logi w czasie rzeczywistym
tail -f output_wavegan/epochs_statistics/epoch_statistics.csv

# Sprawd≈∫ ostatnie checkpointy
ls -la output_wavegan/checkpoints/
```

## üéµ Audio Processing

### Format Wej≈õciowy

- **Sample Rate**: 22050 Hz
- **Duration**: 2.0 sekundy
- **Channels**: Mono (1 kana≈Ç)
- **Format**: WAV, 16-bit

### Preprocessing

- Normalizacja do zakresu [-1, 1]
- Windowing i overlapping dla stabilno≈õci
- Spectral normalization (opcjonalne)

---

**Autor**: Projekt magisterski  
**Ostatnia aktualizacja**: Sierpie≈Ñ 2025  
**Licencja**: MIT
